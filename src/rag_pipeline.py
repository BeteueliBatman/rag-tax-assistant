import os
from typing import List, Dict
from pathlib import Path
import json
from dotenv import load_dotenv
from groq import Groq
from .vector_store import VectorStore

# Load environment variables
load_dotenv()

class RAGPipeline:
    def __init__(self):
        print("ğŸš€ Initializing RAG Pipeline...")
        
        # Vector Store
        print("ğŸ“š Loading vector store...")
        self.vector_store = VectorStore()
        
        # Load chunks
        chunks_file = Path('data/processed/chunks.json')
        if chunks_file.exists():
            with open(chunks_file, 'r', encoding='utf-8') as f:
                chunks = json.load(f)
            
            if self.vector_store.collection.count() == 0:
                print("ğŸ“¦ Building vector store...")
                self.vector_store.add_chunks(chunks)
        
        # Groq API setup - Streamlit Secrets support
        print("ğŸ¤– Connecting to Groq...")
        
        # Try Streamlit secrets first, then environment variable
        groq_key = None
        try:
            import streamlit as st
            groq_key = st.secrets.get("GROQ_API_KEY")
        except:
            pass
        
        if not groq_key:
            groq_key = os.getenv('GROQ_API_KEY')
        
        if not groq_key:
            raise ValueError("âŒ GROQ_API_KEY not found in secrets or .env!")
        
        self.client = Groq(api_key=groq_key)
        self.model = "llama-3.3-70b-versatile"
        
        print("âœ… RAG Pipeline ready!\n")
    
    def create_prompt(self, query: str, context_chunks: List[Dict]) -> tuple:
        """Prompt-áƒ˜áƒ¡ áƒ¨áƒ”áƒ¥áƒ›áƒœáƒ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜áƒ—"""
        
        context_text = ""
        sources = []
        
        for i, chunk in enumerate(context_chunks, 1):
            context_text += f"\n--- áƒ¬áƒ§áƒáƒ áƒ {i} ---\n"
            context_text += f"áƒ“áƒáƒ™áƒ£áƒ›áƒ”áƒœáƒ¢áƒ˜: {chunk['metadata']['title']}\n"
            context_text += f"URL: {chunk['metadata']['source']}\n"
            context_text += f"áƒ¨áƒ˜áƒœáƒáƒáƒ áƒ¡áƒ˜: {chunk['text']}\n"
            
            sources.append({
                'number': i,
                'title': chunk['metadata']['title'],
                'url': chunk['metadata']['source']
            })
        
        prompt = f"""áƒ¨áƒ”áƒœ áƒ®áƒáƒ  AI áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ˜, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª áƒ”áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒ áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ”áƒ‘áƒ¡ áƒ¡áƒáƒ’áƒáƒ“áƒáƒ¡áƒáƒ®áƒáƒ“áƒ áƒ“áƒ áƒ¡áƒáƒ‘áƒáƒŸáƒ áƒ¡áƒáƒ™áƒ˜áƒ—áƒ®áƒ”áƒ‘áƒ¨áƒ˜.

áƒ¨áƒ”áƒœáƒ˜ áƒ“áƒáƒ•áƒáƒšáƒ”áƒ‘áƒáƒ áƒ£áƒáƒáƒ¡áƒ£áƒ®áƒ áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒáƒ¡ áƒ›áƒáƒªáƒ”áƒ›áƒ£áƒšáƒ˜ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜áƒ¡ áƒ¡áƒáƒ¤áƒ£áƒ«áƒ•áƒ”áƒšáƒ–áƒ”.

**áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ•áƒáƒœáƒ˜ áƒ¬áƒ”áƒ¡áƒ”áƒ‘áƒ˜:**
1. áƒ£áƒáƒáƒ¡áƒ£áƒ®áƒ” á²›á²®á²á²šá²á²“ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ¨áƒ˜ áƒáƒ áƒ¡áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ˜áƒœáƒ¤áƒáƒ áƒ›áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ¡áƒáƒ¤áƒ£áƒ«áƒ•áƒ”áƒšáƒ–áƒ”
2. áƒ—áƒ£ áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ¨áƒ˜ áƒáƒ  áƒáƒ áƒ˜áƒ¡ áƒáƒáƒ¡áƒ£áƒ®áƒ˜, áƒáƒ›áƒ‘áƒáƒ‘: "áƒ‘áƒáƒ“áƒ˜áƒ¨áƒ˜, áƒáƒ› áƒ™áƒ˜áƒ—áƒ®áƒ•áƒáƒ–áƒ” áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒáƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ áƒ›áƒáƒ¬áƒáƒ“áƒ”áƒ‘áƒ£áƒš áƒ“áƒáƒ™áƒ£áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ¨áƒ˜."
3. á²§á²á²•á²”á²šá²—á²•á²˜á²¡ áƒ›áƒ˜áƒ£áƒ—áƒ˜áƒ—áƒ” áƒ áƒáƒ›áƒ”áƒšáƒ˜ áƒ¬áƒ§áƒáƒ áƒáƒ“áƒáƒœ áƒ›áƒáƒ“áƒ˜áƒ¡ áƒ˜áƒœáƒ¤áƒáƒ áƒ›áƒáƒªáƒ˜áƒ (áƒ¬áƒ§áƒáƒ áƒ 1, áƒ¬áƒ§áƒáƒ áƒ 2, áƒ“áƒ áƒ.áƒ¨.)
4. áƒ˜áƒ§áƒáƒ•áƒ˜ áƒ–áƒ£áƒ¡áƒ¢áƒ˜ áƒ“áƒ áƒ™áƒáƒœáƒ™áƒ áƒ”áƒ¢áƒ£áƒšáƒ˜
5. áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ” áƒ›áƒáƒ áƒ¢áƒ˜áƒ•áƒ˜, áƒ’áƒáƒ¡áƒáƒ’áƒ”áƒ‘áƒ˜ áƒ¥áƒáƒ áƒ—áƒ£áƒšáƒ˜ áƒ”áƒœáƒ

**áƒ™áƒáƒœáƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ˜ (áƒ“áƒáƒ™áƒ£áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜áƒ“áƒáƒœ):**
{context_text}

**áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒšáƒ˜áƒ¡ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ:** {query}

**áƒ¨áƒ”áƒœáƒ˜ áƒáƒáƒ¡áƒ£áƒ®áƒ˜:**"""
        
        return prompt, sources
    
    def answer_question(self, query: str, n_results=5) -> Dict:
        """áƒ™áƒ˜áƒ—áƒ®áƒ•áƒáƒ–áƒ” áƒáƒáƒ¡áƒ£áƒ®áƒ˜áƒ¡ áƒ’áƒ”áƒœáƒ”áƒ áƒ˜áƒ áƒ”áƒ‘áƒ"""
        
        print(f"ğŸ” Searching relevant documents for: {query}")
        
        # 1. Vector Search
        relevant_chunks = self.vector_store.search(query, n_results=n_results)
        
        print(f"âœ“ Found {len(relevant_chunks)} relevant chunks")
        
        # 2. Prompt-áƒ˜áƒ¡ áƒ¨áƒ”áƒ¥áƒ›áƒœáƒ
        prompt, sources = self.create_prompt(query, relevant_chunks)
        
        # 3. Groq-áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ«áƒáƒ®áƒ”áƒ‘áƒ
        print("ğŸ¤– Generating answer...")
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "áƒ¨áƒ”áƒœ áƒ®áƒáƒ  áƒ“áƒáƒ›áƒ®áƒ›áƒáƒ áƒ” AI áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ˜ áƒ¡áƒáƒ’áƒáƒ“áƒáƒ¡áƒáƒ®áƒáƒ“áƒ áƒ¡áƒáƒ™áƒ˜áƒ—áƒ®áƒ”áƒ‘áƒ¨áƒ˜."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            answer = response.choices[0].message.content
            
            print("âœ“ Answer generated!\n")
            
            return {
                'query': query,
                'answer': answer,
                'sources': sources,
                'relevant_chunks': relevant_chunks
            }
        
        except Exception as e:
            print(f"âŒ Error generating answer: {e}")
            return {
                'query': query,
                'answer': f"áƒ‘áƒáƒ“áƒ˜áƒ¨áƒ˜, áƒáƒáƒ¡áƒ£áƒ®áƒ˜áƒ¡ áƒ’áƒ”áƒœáƒ”áƒ áƒ˜áƒ áƒ”áƒ‘áƒ˜áƒ¡áƒáƒ¡ áƒ›áƒáƒ®áƒ“áƒ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: {str(e)}",
                'sources': sources,
                'relevant_chunks': relevant_chunks
            }

def main():
    rag = RAGPipeline()
    
    print("\n" + "="*80)
    print("ğŸ§ª Testing RAG Pipeline")
    print("="*80 + "\n")
    
    test_questions = [
        "áƒ áƒ áƒáƒ áƒ˜áƒ¡ áƒ“áƒ¦áƒ’?",
        "áƒ áƒáƒ’áƒáƒ  áƒ£áƒœáƒ“áƒ áƒ›áƒáƒ•áƒáƒ®áƒ“áƒ˜áƒœáƒ áƒ¡áƒáƒ‘áƒáƒŸáƒ áƒ“áƒ”áƒ™áƒšáƒáƒ áƒ˜áƒ áƒ”áƒ‘áƒ?",
    ]
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*80}")
        print(f"áƒ¢áƒ”áƒ¡áƒ¢áƒ˜ {i}/{len(test_questions)}")
        print(f"{'='*80}\n")
        
        result = rag.answer_question(question)
        
        print(f"â“ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ: {result['query']}")
        print(f"\nğŸ’¬ áƒáƒáƒ¡áƒ£áƒ®áƒ˜:\n{result['answer']}")
        
        print(f"\nğŸ“š áƒ¬áƒ§áƒáƒ áƒáƒ”áƒ‘áƒ˜:")
        for source in result['sources']:
            print(f"  â€¢ {source['title']}")
            print(f"    {source['url']}")
        
        print()

if __name__ == "__main__":
    main()